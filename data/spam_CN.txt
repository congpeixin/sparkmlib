岗位职责：1、负责大数据平台体系的建设以及大数据团队搭建工作；
2、基于数据挖掘和机器学习算法，针对业务场景设计和完善用户模型、内容模型和特征体系；
3、通过数据挖掘发挥数据价值，助力业务增长，并通过预测和推荐更好的提升产品转化
职位要求
1、统计学、数学、计算机、管理科学、经济学等相关专业全日制统招本科以上学历；
2、熟悉Hadoop、Hive、Spark或其它开源数据挖掘（R、SPSS、SAS、python）等项目，能够解决数据分析过程中遇到的问题；
3、掌握常用的机器学习算法，如协同过滤、逻辑回归、GBDT等，并有独立完整的建模实践经验；
4、有大规模数据分析、推荐、广告或搜索算法研发经验者优先；
5、思维敏捷，良好的逻辑分析能力、良好的沟通及管理能力。

岗位职责：
	围绕**生态圈、网器、APP、ubot机器人等业务需求，建立语义解析系统，构建语义解析知识库。
	负责业务产线的算法模型的搭建和优化，包括智能空调的舒适度曲线、智能热水器的节能优化算法等。
	负责多轮对话系统的搭建，跟进前沿技术，协助主管做好内外部需求的调研、梳理、研发计划、产品迭代等工作；
	精通至少一个NLP技术模块， 比如 语义解析、属性抽取、分词、主题模型 等；
	对多轮对话有研发经验者优先，在NLG、NLU、DM方面具备实际的动手研发经验；
	对DNN、word embedding等深度学习方法在NLP上的应用有实践者优先
	硕士或博士毕业


Hive on Spark
岗位职责:
1.Hadoop生态圈环境搭建、性能调优，结合德邦应用需求以及现状，设计优化Hadoop环境，相关参数
配置与调试，完成环境压力测试；
2.大数据开发、测试、部署流程设计；结合现有流程，梳理开发规范；
3.大数据应用开发；
4.实时计算应用；Spark Streaming实时计算技术。
任职要求：
1.4年以上大数据经验；
2.精通Hadoop、Spark、Hive、Hbase等常用大数据技术；
3.流式计算Spark streaming实时数据处理技术项目经验；
4.具有HIVE数据仓库开发经验；
5.熟练编写Linux脚本以及Python脚本；
6.熟练掌握shell, 熟悉Java开发；
7.熟悉大数据分布式环境架构的搭建，能独立完成大数据环境的监控及调优；
Storm：
任职要求：
4年以上大数据经验
精通Hadoop、Storm、Hive、Hbase等常用大数据技术
流式计算Storm实时数据处理技术项目经验
具有数据仓库开发经验，如ETL、OLAP等
熟练编写Linux脚本以及Python脚本
熟练掌握shell, 熟悉Java开发
熟悉大数据分布式环境架构的搭建，能独立完成大数据环境的监控及调优


岗位职责：
1、负责hadoop/spark平台技术引进和推广，并能结合用户需求快速落地推广；
2、负责大数据分析需求设计和开发，包括数据集市、实时分析、数据展示等的开发，并交付生产，确保输出成果；
3、负责项目成果在公司内的推广应用、培训，以及对外对内合作交流，不断提升公司的技术和应用能力。
任职资格：
1、熟练使用java，Scala语言；
2、智能内容的推荐
3、具有2年以上BI/报表相关工作经验，熟练掌握hadoop，hive，Spark开发，有一定调优经验；
4、有良好的口头和书面表达能力；
5、良好的结构化问题解决能力
